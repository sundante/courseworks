{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32065630-f69c-431b-8f19-c8e2a847cdca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa6c10-6981-41de-a18f-e4c83400167f",
   "metadata": {},
   "source": [
    "- Fixed-length: Splitting documents into fixed-size chunks. It’s easy to do, but sometimes chunks may not align with logical breaks, so you could split important info or include irrelevant content.\n",
    "- Sentence-based: Breaking documents into sentences keeps sentences intact, which is great for detailed analysis. However, it may lead to too many chunks or lose context when sentences are too short to capture full ideas.\n",
    "- Paragraph-based: Dividing by paragraphs helps keep the context intact, but paragraphs may be too long, making retrieval and processing less efficient.\n",
    "- Semantic chunking: Chunks are created based on meaning, like sections or topics. This keeps the context clear but is harder to implement since it needs advanced text analysis.\n",
    "- Sliding window: Chunks overlap by sliding over the text. This ensures important info isn't missed but can be computationally expensive and may result in repeated information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace3f0e-4683-4ee6-81b0-e37f123d4234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chunking: Fixed-Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a02b18-f0ca-47ec-9a07-99ef63aef844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fixed-length chunking by character count\n",
    "def chunk_text_fixed(text, max_chars=500):\n",
    "    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "document = \"...\"  # a long text document\n",
    "chunks = chunk_text_fixed(document, max_chars=1000)\n",
    "print(f\"Created {len(chunks)} fixed-size chunks.\")\n",
    "print(chunks[0][:100])  # preview first 100 chars of the first chunkb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56f2e1-15be-4cc7-9fd8-a898190da53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chunking: Recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291de79-9f64-4586-9acb-3ecb139a8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separators list tells the splitter to prefer paragraph breaks, then line breaks, then spaces.\n",
    "# here each chunk shares 50 characters with the next – which can help preserve context at boundaries so that important info cut off at the end of one chunk is still present at the start of the next chunk. \n",
    "\n",
    "# Using LangChain's RecursiveCharacterTextSplitter for rule-based chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 800,        # target chunk size in characters (or tokens)\n",
    "    chunk_overlap = 50,      # overlap to maintain context between chunks\n",
    "    separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]  \n",
    "    # The splitter will try to split by double newline (paragraph), then newline, then space, then as last resort character.\n",
    ")\n",
    "chunks = text_splitter.split_text(document)\n",
    "print(f\"Created {len(chunks)} chunks with recursive splitting.\")\n",
    "print(chunks[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b9b0-0242-49c8-951d-5dba407114c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chunking: Semantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bf783-6361-456d-b6a1-6eacabeb9dd6",
   "metadata": {},
   "source": [
    "- Semantic chunking aims to split text based on meaning or topic shifts rather than hard rules of length or explicit delimiters.\n",
    "- slide a window through the text and split when the similarity between adjacent sentences drops below a threshold (indicating a topic shift).\n",
    "- You can also leverage summarization: recursively split the document and summarize sections to decide if splitting further is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf34a8-a11a-4b51-a72c-0cc0a5b64b06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chunking: Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7eb0fc-ce94-4f94-8ee8-5096305ef90d",
   "metadata": {},
   "source": [
    "- A sliding window approach creates overlapping chunks by moving a window of fixed size through the text with a certain stride.\n",
    "- For example, take 500 words at a time but start the next chunk 300 words in (thus 200-word overlap). This ensures high coverage (every part of the text appears in some chunk) and preserves context between adjacent chunks.\n",
    "- Sliding window chunking is common when you absolutely need to capture local context and can’t afford to miss something at a boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533e6aa-d315-4d7e-9530-042ef37b7491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chunking: Gotchas and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a6616-6f86-4263-bd5f-f1c6933a3aa2",
   "metadata": {},
   "source": [
    "- Chunk Size vs Context Window: Always design chunking with your target LLM’s context length in mind.\n",
    "- Overlap Trade-off: Use overlapping chunks if missing boundary information is a concern, but be mindful of the inflation in chunk count. A small overlap (10–20% of chunk length) is often enough to catch important context.\n",
    "- Metadata: Maintain metadata with each chunk. For example, store the document title, section name, page number, or other identifiers alongside the chunk.\n",
    "- Don’t Overchunk Extremely Short Texts: If some documents are already short (short articles or FAQs), you might not need to chunk them at all.\n",
    "- Multilingual Considerations: If your data is multilingual, chunking by sentence/paragraph still works, but remember that different languages have different average word lengths and tokenization behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a15a2-98e1-4391-a76f-9d1fac95bcaa",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Embeddings are the backbone of the RAG retrieval system’s semantic memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee1e92-80b7-46f0-8f49-c240860204af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
